/*
 * Copyright (c) 2007-2013 Concurrent, Inc. All Rights Reserved.
 *
 * Project and contact information: http://www.cascading.org/
 *
 * This file is part of the Cascading project.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
import java.text.SimpleDateFormat
import java.io.FileOutputStream
import org.apache.tools.ant.filters.ReplaceTokens

apply from: 'etc/version.gradle'
apply from: 'etc/s3Upload.gradle'

apply plugin:'java' 
apply plugin:'maven' 
apply plugin: 'idea'
apply plugin: 'eclipse'

apply from: 'etc/providedCompile.gradle'

ext.buildTimestamp = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(
                                        new Date())
ext.buildDate = new SimpleDateFormat("yyyyMMdd").format( new Date())
ext.finalJarName = "${rootProject.name}-${buildDate}.jar"
ext.finalTarName = "${rootProject.name}-${buildDate}.tgz"
ext.assemblyDirName = "build/assemble"
ext.hadoopVersion = "1.0.4"

ext.cascadingVersion = '2.2.0-+'

// set property to use locally installed cascading builds
// otherwise wip releases will be pulled from conjars
if( System.properties[ 'multitool.release.local' ] ) 
      cascadingVersion = '2.2.0-wip-dev'

repositories{
    mavenLocal()
    mavenCentral()
    mavenRepo name: 'conjars', url: 'http://conjars.org/repo/'
}

dependencies{
    compile group: 'cascading', name: 'cascading-core', version: cascadingVersion
    compile group: 'cascading', name: 'cascading-hadoop', version: cascadingVersion

    testCompile group: 'junit', name: 'junit', version: '4.11'
    testCompile group: 'cascading', name:'cascading-core', version: cascadingVersion, classifier: 'tests', changing: true
    testCompile group: 'org.apache.hadoop', name: 'hadoop-test', version: hadoopVersion
    testCompile group: 'org.slf4j', name: 'slf4j-log4j12', version: '1.6.1'
    
    providedCompile group: 'org.slf4j', name: 'slf4j-api', version: '1.6.1'
    providedCompile group: 'org.apache.hadoop', name: 'hadoop-core', version: hadoopVersion
}


jar {
  description = "Assembles a Hadoop ready jar file"
  archiveName = finalJarName
  from("version.properties"){ 
      filter( ReplaceTokens, tokens: [
              'builddate': "${buildDate}".toString(), 'commit': "${commit}".toString()
      ] ) 
  } 
  doFirst {
    into('lib') {
      from configurations.compile
    }
  }

  manifest {
    attributes "Main-Class": "multitool/Main",
               'Build-Time': "${buildTimestamp}"
  }
}

test{
    maxHeapSize = "756m"
    systemProperty "hadoop.log.dir" ,"build/test/log"
}


task mtTest() << { task ->
    description = "runs the test suite for the shell script wrapper"
    Process proc = ["/bin/sh", "src/test/shell/mt/helper/roundup.sh", 
      "src/test/shell/mt/*.sh"].execute()
    proc.consumeProcessErrorStream(System.err)
    proc.consumeProcessOutputStream(System.out)
    if (proc.waitFor() != 0) {
        throw new RuntimeException('exec failed')
    }
} 


task assembleTarballStructure(dependsOn: jar) << {
    def targetDirName = "${assemblyDirName}/${rootProject.name}-${buildDate}"
    copy{
        from("bin")
        into("${targetDirName}/bin")
    }
    copy{
        from("data")
        into("${targetDirName}/data")
    }
    copy{
        from(".")
        include("apl.txt", "COMMANDS.md", "README.md")
        into(targetDirName)
    }
    copy{
        from("build/libs")
        include(finalJarName)
        into(targetDirName)
    }

}

task buildTarball(type: Tar, dependsOn: assembleTarballStructure){
    baseName = "${rootProject.name}-${buildDate}"
    destinationDir = new File("${s3Upload.source}")
    compression = Compression.GZIP
    from(assemblyDirName)
}

task assembleDist(dependsOn: [buildTarball]) << {

     file( "${s3Upload.source}/latest.txt" ).write( "http://${s3Upload.destination}${finalTarName}" )
     file( "${s3Upload.source}/latest-jar.txt" ).write( "http://${s3Upload.destination}${finalJarName}" )
     copy{
        from("build/libs")
        include(finalJarName)
        into("${s3Upload.source}")
     }
     s3Upload.dependsOn =  [assembleDist, test, mtTest]
}


task markdown(dependsOn: jar) << { task ->
    description = "updates COMMANDS.md markdown file"
    Process proc = 
        ["bin/multitool", "--markdown"].execute()
    proc.consumeProcessErrorStream(System.err)
    proc.consumeProcessOutputStream(new FileOutputStream("COMMANDS.md"))
    if (proc.waitFor() != 0) {
        throw new RuntimeException('exec failed')
    }
}
